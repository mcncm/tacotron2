{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', r'as a synonym of type is deprecated')\n",
    "\n",
    "from hparams import create_hparams\n",
    "hparams = create_hparams()\n",
    "hparams.batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n",
    "from convert_model import update_model\n",
    "\n",
    "from train import prepare_dataloaders\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"tacotron2_statedict.pt\"\n",
    "checkpoint_path = 'new-test-outdir/checkpoint_27000'\n",
    "checkpoint_name = os.path.basename(checkpoint_path)\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "\n",
    "PROJ_DIR = '/home/mcncm/class/6.867/proj'\n",
    "OUT_DIR = os.path.join(PROJ_DIR, 'tacotron2/new-test-outdir')\n",
    "FIGS_DIR = os.path.join(PROJ_DIR, 'writeup/figures', checkpoint_name)\n",
    "if not os.path.exists(FIGS_DIR):\n",
    "    os.mkdir(FIGS_DIR)\n",
    "AUDIO_DIR = os.path.join(PROJ_DIR, 'audio', checkpoint_name)\n",
    "if not os.path.exists(AUDIO_DIR):\n",
    "    os.mkdir(AUDIO_DIR)\n",
    "\n",
    "fontsize=14\n",
    "\n",
    "def plot_data(filename, data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')\n",
    "    plt.savefig(os.path.join(FIGS_DIR, filename))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_spectrogram(filename, spec, figsize=(16, 4), colorbar=False):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "    im = axes.imshow(spec, aspect='auto', origin='bottom', \n",
    "                       interpolation='none')\n",
    "    axes.set_xlabel('Frame', fontsize=fontsize)\n",
    "    axes.set_ylabel('FFT bin', fontsize=fontsize)\n",
    "    \n",
    "    if colorbar:\n",
    "        divider = make_axes_locatable(axes)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(im, cax=cax)\n",
    "\n",
    "    plt.savefig(os.path.join(FIGS_DIR, filename))\n",
    "    plt.show()\n",
    "\n",
    "def save_audio(filename, audio):\n",
    "    def center(data):\n",
    "        \"\"\"Rescale to [0, 1]\"\"\"\n",
    "        data -= np.max(data) + np.min(data)\n",
    "        data = data/np.max(data)\n",
    "        return data\n",
    "        \n",
    "    path = os.path.join(AUDIO_DIR, filename)\n",
    "    audio = center(audio.astype(np.float32))\n",
    "    wavfile.write(path, SAMPLE_RATE, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load WaveGlow for mel2audio synthesis and denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "waveglow_path = 'waveglow_256channels_ljs_v2.pt'\n",
    "waveglow = update_model(torch.load(waveglow_path)['model']) \n",
    "waveglow.cuda().eval()\n",
    "for k in waveglow.convinv:\n",
    "    k.float()\n",
    "denoiser = Denoiser(waveglow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valset, collate_fn = prepare_dataloaders(hparams)\n",
    "\n",
    "def val_text(i: int):\n",
    "    return valset[i][0]\n",
    "\n",
    "def val_spec(i: int):\n",
    "    return valset[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(valset, sampler=None, num_workers=1,\n",
    "                        shuffle=False, batch_size=4,\n",
    "                        pin_memory=False, collate_fn=collate_fn)\n",
    "x, y = model.parse_batch(next(iter(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_inputs = model.embedding(x[0]).transpose(1, 2)\n",
    "encoder_outputs = model.encoder.inference(embedded_inputs)\n",
    "\n",
    "length = encoder_outputs.shape[1]\n",
    "# reshaping encoder outputs:\n",
    "# need shape (N, L, ref_embedding_dim)\n",
    "ref_encoder_outputs = model.ref_encoder(y[0]).unsqueeze(1).repeat(1, length, 1)\n",
    "\n",
    "print(encoder_outputs.shape)\n",
    "print(ref_encoder_outputs.shape)\n",
    "\n",
    "torch.cat((encoder_outputs[0,:,:], ref_encoder_outputs[0,:,:]), -1)\n",
    "mel_outputs, gate_outputs, alignments = model.decoder.inference(\n",
    "             torch.cat((encoder_outputs[0,:,:], ref_encoder_outputs[0,:,:]), -1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_mels(x, y):\n",
    "    r\"\"\"Insert y as the mels in x\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_spec(audio_data, threshold=-1e-7):\n",
    "    r\"\"\"Find where data is last nonzero, then return up to that point\n",
    "    \"\"\"\n",
    "    mins, _ = torch.min(audio_data, 0)\n",
    "    return audio_data[:, (mins < threshold).nonzero().squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x)\n",
    "\n",
    "common_name = 'new_model'\n",
    "\n",
    "# audio_data = denoiser(audio, strength=0.02).data.cpu().numpy()\n",
    "specs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(y_pred[0].shape[0]):\n",
    "        spec = trim_spec(y_pred[0][i,...])\n",
    "        specs.append(spec.cpu())\n",
    "        audio_data = waveglow.infer(spec.unsqueeze(0), sigma=0.666)\n",
    " \n",
    "        audio_data = denoiser(audio_data, strength=0.02).data.cpu().numpy()\n",
    "        save_audio(common_name + \"_{}\".format(i) + '.wav', audio_data)\n",
    "\n",
    "        plot_spectrogram(common_name + \"_{}\".format(i) + '.png',\n",
    "                         spec.float().data.cpu().numpy(),\n",
    "                         figsize=(8, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_transfer = model(x, y[0][(1,2,3,0),...])\n",
    "\n",
    "common_name = 'prosody_11k_steps_transfer'\n",
    "\n",
    "# audio_data = denoiser(audio, strength=0.02).data.cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    for i in range(y_pred_transfer[0].shape[0]):\n",
    "        spec_transfer = trim_spec(y_pred_transfer[0][i,...])\n",
    "        audio_data = waveglow.infer(spec_transfer.unsqueeze(0), sigma=0.666)\n",
    " \n",
    "        audio_data = denoiser(audio_data, strength=0.02).data.cpu().numpy()\n",
    "        save_audio(common_name + \"_{}\".format(i) + '.wav', audio_data)\n",
    "\n",
    "        plot_spectrogram(common_name + \"_{}\".format(i) + '.png',\n",
    "                         spec_transfer.float().data.cpu().numpy(),\n",
    "                         figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try perturbing the reference encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_specs = [trim_spec(y[0][i,...]) for i in range(y[0].shape[0])]\n",
    "embeddings = [model.reference_encoder(true_specs[i].unsqueeze(0)) for i in range(y[0].shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference encoding PCA\n",
    "\n",
    "`train_ref_encodings` should be a matrix of the reference encodings, such that\n",
    "`train_ref_encodings[i,:]` contains the reference encoding for example i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number 0\n",
      "batch number 10\n",
      "batch number 20\n",
      "batch number 30\n",
      "batch number 40\n",
      "batch number 50\n",
      "batch number 60\n",
      "batch number 70\n",
      "batch number 80\n",
      "batch number 90\n",
      "batch number 100\n",
      "batch number 110\n",
      "batch number 120\n",
      "batch number 130\n",
      "batch number 140\n",
      "batch number 150\n",
      "batch number 160\n",
      "batch number 170\n",
      "batch number 180\n",
      "batch number 190\n",
      "batch number 200\n",
      "batch number 210\n",
      "batch number 220\n",
      "batch number 230\n",
      "batch number 240\n",
      "batch number 250\n",
      "batch number 260\n",
      "batch number 270\n",
      "batch number 280\n",
      "batch number 290\n",
      "batch number 300\n",
      "batch number 310\n",
      "batch number 320\n",
      "batch number 330\n",
      "batch number 340\n",
      "batch number 350\n",
      "batch number 360\n",
      "batch number 370\n",
      "batch number 380\n",
      "batch number 390\n",
      "batch number 400\n",
      "batch number 410\n",
      "batch number 420\n",
      "batch number 430\n",
      "batch number 440\n",
      "batch number 450\n",
      "batch number 460\n",
      "batch number 470\n",
      "batch number 480\n",
      "batch number 490\n",
      "batch number 500\n",
      "batch number 510\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_ref_encodings = np.load(os.path.join(OUT_DIR, \"train_ref_encodings.npy\"))\n",
    "except:\n",
    "    #hparams_big_batch = create_hparams()\n",
    "    #hparams_big_batch.batch_size = 48\n",
    "    #train_loader, valset, collate_fn = prepare_dataloaders(hparams_big_batch)\n",
    "    train_ref_encodings = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        if i % 10 == 0:\n",
    "            print(\"batch number\", i)\n",
    "        x, y = model.parse_batch(batch)\n",
    "        mels = x[2]\n",
    "        encodings = model.ref_encoder(mels)  # TODO: replace with .inference\n",
    "        train_ref_encodings.append(encodings.cpu().detach().numpy())\n",
    "    train_ref_encodings = np.concatenate(train_ref_encodings)\n",
    "    np.save(os.path.join(OUT_DIR, \"train_ref_encodings.npy\"), train_ref_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually calculate the singular value decomposition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_u = np.load(os.path.join(OUT_DIR, \"train_u.npy\"))\n",
    "    train_s = np.load(os.path.join(OUT_DIR, \"train_s.npy\"))\n",
    "    train_vh = np.load(os.path.join(OUT_DIR, \"train_vh.npy\"))\n",
    "except:\n",
    "    train_u, train_s, train_vh = np.linalg.svd(train_ref_encodings)\n",
    "    np.save(os.path.join(OUT_DIR, \"train_u.npy\"), train_u)\n",
    "    np.save(os.path.join(OUT_DIR, \"train_s.npy\"), train_s)\n",
    "    np.save(os.path.join(OUT_DIR, \"train_vh.npy\"), train_vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot the spectrum of singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_singular_values(filename, train_s, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "    axes.plot(train_s)\n",
    "    axes.set_xlabel('Principal component number')\n",
    "    axes.set_ylabel('Singular value')\n",
    "    plt.savefig(os.path.join(FIGS_DIR, filename))\n",
    "    plt.show()\n",
    "    \n",
    "plot_singular_values('ref_singular_values.png', train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mcncm/class/6.867/proj/writeup/figures/checkpoint_27000'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIGS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff_sigma_matrix(sigmas, tau):\n",
    "    r\"\"\"Return the sigma matrix without \n",
    "    \"\"\"\n",
    "    sigs = np.diag(sigmas * (sigmas >= tau))\n",
    "    return np.concatenate((sigs, np.zeros((n_users - n_movies, n_movies))))\n",
    "\n",
    "def reconstruct_threshold(tau):\n",
    "    r\"\"\"Estimate a matrix by singular value thresholding with cutoff tau.\"\"\"\n",
    "    return train_u @ cutoff_sigma_matrix(train_s, tau) @ train_u\n",
    "\n",
    "def reconstruct_sigmas_list(sigmas_list):\n",
    "    r\"\"\"Estimate a matrix using the principal component indices in a list\"\"\"\n",
    "    return sum((np.outer(train_s[i] * train_u[:,i], train_vh[i, :])\n",
    "                for i in sigmas_list))\n",
    "\n",
    "def reconstruct_top_sigmas(n_sigmas):\n",
    "    r\"\"\"Estimate a matrix using the biggest singular values\"\"\"\n",
    "    return reconstruct_sigmas_list(range())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little tools for hotswapping the encoder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandEncoder(nn.Module):\n",
    "    def __init__(self, dimension, amplitude=5):\n",
    "        super(RandEncoder, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.amplitude = amplitude\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.amplitude * torch.rand(hparams.batch_size, self.dimension).cuda()\n",
    "\n",
    "\n",
    "class RandPerturbationEncoder(nn.Module):\n",
    "    def __init__(self, other, dimension, amplitude=5):\n",
    "        super(RandPerturbationEncoder, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.amplitude = amplitude\n",
    "        self.other = other\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rand_vec = self.amplitude * (torch.rand(hparams.batch_size, self.dimension).cuda() - 0.5)\n",
    "        return self.other(x) + rand_vec\n",
    "\n",
    "    \n",
    "class PCAEncoder(nn.Module):\n",
    "    def __init__(self, other, dimension, components):\n",
    "        super(PCAEncoder, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.components = components\n",
    "    \n",
    "    def forward(self, x)\n",
    "        \n",
    "\n",
    "    \n",
    "class ZeroEncoder(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(ZeroEncoder, self).__init__()\n",
    "        self.dimension = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.zeros(hparams.batch_size, self.dimension).cuda()\n",
    "\n",
    "\n",
    "class EncoderContext():\n",
    "    r\"\"\"Swap in a new encoder module on the fly with a `with` statement.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, encoder):\n",
    "        self.model = model\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.old_encoder = self.model.reference_encoder\n",
    "        self.model._modules['reference_encoder'] = self.encoder\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print('exiting')\n",
    "        self.model._modules['reference_encoder'] = self.old_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_name = 'rand'\n",
    "\n",
    "with EncoderContext(model, RandEncoder(128)):\n",
    "    y_pred_rand = model(x, y[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(y_pred_rand[0].shape[0]):\n",
    "            spec_transfer = trim_spec(y_pred_rand[0][i,...])\n",
    "            audio_data = waveglow.infer(spec_transfer.unsqueeze(0), sigma=0.666)\n",
    " \n",
    "            audio_data = denoiser(audio_data, strength=0.02).data.cpu().numpy()\n",
    "            save_audio(common_name + \"_{}\".format(i) + '.wav', audio_data)\n",
    "\n",
    "            plot_spectrogram(common_name + \"_{}\".format(i) + '.png',\n",
    "                             spec_transfer.float().data.cpu().numpy(),\n",
    "                             figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_name = 'zero'\n",
    "\n",
    "with EncoderContext(model, ZeroEncoder(128)):\n",
    "    y_pred_rand = model(x, y[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(y_pred_rand[0].shape[0]):\n",
    "            spec_transfer = trim_spec(y_pred_rand[0][i,...])\n",
    "            audio_data = waveglow.infer(spec_transfer.unsqueeze(0), sigma=0.666)\n",
    " \n",
    "            audio_data = denoiser(audio_data, strength=0.02).data.cpu().numpy()\n",
    "            save_audio(common_name + \"_{}\".format(i) + '.wav', audio_data)\n",
    "\n",
    "            plot_spectrogram(common_name + \"_{}\".format(i) + '.png',\n",
    "                             spec_transfer.float().data.cpu().numpy(),\n",
    "                             figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly perturbed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_name = 'pert'\n",
    "\n",
    "reference_encoder = model.reference_encoder\n",
    "with EncoderContext(model, RandPerturbationEncoder(reference_encoder, 128, amplitude=5)):\n",
    "    y_pred_rand = model(x, y[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(y_pred_rand[0].shape[0]):\n",
    "            spec_transfer = trim_spec(y_pred_rand[0][i,...])\n",
    "            audio_data = waveglow.infer(spec_transfer.unsqueeze(0), sigma=0.666)\n",
    " \n",
    "            audio_data = denoiser(audio_data, strength=0.02).data.cpu().numpy()\n",
    "            save_audio(common_name + \"_{}\".format(i) + '.wav', audio_data)\n",
    "\n",
    "            plot_spectrogram(common_name + \"_{}\".format(i) + '.png',\n",
    "                             spec_transfer.float().data.cpu().numpy(),\n",
    "                             figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff from original inference.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Institute has the finest professors.\"\n",
    "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('triple_spectrogram.png',\n",
    "          (mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_name = 'institute_5k_steps'\n",
    "\n",
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "    data = audio[0].data.cpu().numpy()\n",
    "    save_audio(common_name + '.wav', data)\n",
    "\n",
    "plot_spectrogram(common_name + '.png',\n",
    "                 mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "                 figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthesize audio from spectrogram using WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs_postnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio[0].data.cpu().numpy()\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Remove WaveGlow bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
    "ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6867",
   "language": "python",
   "name": "6867"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
